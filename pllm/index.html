<!DOCTYPE html>
<html lang="en-GB">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- DNS Prefetch and Preconnect for Performance -->
  <link rel="dns-prefetch" href="//fonts.googleapis.com">
  <link rel="dns-prefetch" href="//cdnjs.cloudflare.com">
  <link rel="preconnect" href="https://fonts.googleapis.com" crossorigin>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://cdnjs.cloudflare.com" crossorigin>

  <!-- SEO Meta Tags -->
  <meta name="description" content="Personalised LLM (PLLM) for emotion-aware human-robot and human-computer interaction using real-time EEG signals. Published in MDPI Sensors 2025.">
  <meta name="keywords" content="personalised large language model, PLLM, EEG, emotion recognition, human-robot interaction, HRI, human-computer interaction, HCI, adaptive AI, MDPI Sensors 2025, Khashayar Ghamati, Streamlit, real-time AI, neuroadaptive AI, OpenAI, agentic AI, personalisation, machine learning, affective computing, continual learning, dialogue system, emotion-adaptive chatbot, LLM fine-tuning, multi-modal AI, NeuroSense dataset">
  <meta name="author" content="Khashayar Ghamati, Maryam Banitalebi Dehkordi, Abolfazl Zaraki">
  <meta name="robots" content="index, follow">

  <!-- Open Graph -->
  <meta property="og:title" content="Personalised LLM for Emotion-Aware HRI/HCI | MDPI Sensors 2025">
  <meta property="og:description" content="Emotion-adaptive AI using EEG signals for real-time personalisation. PLLM enables context-aware dialogue in human-robot interaction.">
  <meta property="og:image" content="https://ghamati.com/pllm/f1.jpg">
  <meta property="og:type" content="article">
  <meta property="og:url" content="https://ghamati.com/pllm/">
  <meta property="og:site_name" content="Khashayar Ghamati - AI Research">
  <meta property="og:locale" content="en_GB">
  <meta property="article:author" content="Khashayar Ghamati">
  <meta property="article:published_time" content="2025-03-24">
  <meta property="article:section" content="Artificial Intelligence">
  <meta property="article:tag" content="personalised AI">
  <meta property="article:tag" content="EEG">
  <meta property="article:tag" content="emotion recognition">
  <meta property="article:tag" content="human-robot interaction">

  <!-- Twitter Card -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Personalised LLM for Emotion-Aware HRI/HCI | Sensors 2025">
  <meta name="twitter:description" content="EEG-driven personalisation in LLM-based dialogue for human-robot interaction, published in MDPI Sensors 2025.">
  <meta name="twitter:image" content="https://ghamati.com/pllm/f1.jpg">
  <meta name="twitter:creator" content="@khashayarghamati">

  <link rel="canonical" href="https://ghamati.com/pllm/">

  <title>Personalised LLM for Emotion-Aware HRI | MDPI Sensors 2025</title>

  <!-- Shared MD3 Design System -->
  <link rel="stylesheet" href="/css/material-design.css">

  <!-- Google Fonts -->
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Playfair+Display:wght@400;600;700&display=swap">

  <!-- Font Awesome Icons -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" integrity="sha512-Kc323vGBEqzTmouAECnVceyQqyqdsSiqLQISBL29aUW4U/M7pSPA/gEUZQqv1cwx4OnYxTxve5UMg5GT6L4JJg==" crossorigin="anonymous" referrerpolicy="no-referrer">

  <!-- Structured Data -->
  <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "ScholarlyArticle",
      "headline": "Towards AI-Powered Applications: The Development of a Personalised LLM for HRI and HCI",
      "author": [
        {
          "@type": "Person",
          "name": "Khashayar Ghamati",
          "affiliation": {
            "@type": "Organization",
            "name": "University of Hertfordshire"
          },
          "url": "https://ghamati.com",
          "sameAs": [
            "https://scholar.google.com/citations?user=zRG8t_oAAAAJ&hl=en",
            "https://orcid.org/0009-0002-6416-3127"
          ]
        },
        {
          "@type": "Person",
          "name": "Maryam Banitalebi Dehkordi",
          "affiliation": {
            "@type": "Organization",
            "name": "University of Hertfordshire"
          }
        },
        {
          "@type": "Person",
          "name": "Abolfazl Zaraki",
          "affiliation": {
            "@type": "Organization",
            "name": "University of Hertfordshire"
          }
        }
      ],
      "datePublished": "2025-03-24",
      "url": "https://ghamati.com/pllm/",
      "image": "https://ghamati.com/pllm/f1.jpg",
      "inLanguage": "en",
      "publisher": {
        "@type": "Organization",
        "name": "MDPI Sensors",
        "url": "https://www.mdpi.com/journal/sensors"
      },
      "about": [
        "personalised LLM",
        "EEG",
        "human-robot interaction",
        "emotion recognition",
        "adaptive AI",
        "machine learning",
        "affective computing",
        "continual learning",
        "neuroadaptive AI",
        "dialogue systems"
      ],
      "description": "This work presents a Personalised Large Language Model (PLLM) for real-time emotion-adaptive dialogue, integrating EEG data to personalise LLM behaviour in HRI/HCI. Published in MDPI Sensors 2025.",
      "keywords": "personalised LLM, EEG, emotion recognition, human-robot interaction, adaptive AI, neuroadaptive systems",
      "isAccessibleForFree": true,
      "license": "https://creativecommons.org/licenses/by/4.0/",
      "creativeWorkStatus": "Published",
      "citation": "Ghamati, K.; Dehkordi, M.B.; Zaraki, A. Towards AI-Powered Applications: The Development of a Personalised LLM for HRI and HCI. Sensors 2025, 25, 2024. https://doi.org/10.3390/s25072024"
    }
  </script>

  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-HV1K905FF2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-HV1K905FF2');
  </script>
</head>
<body>

<a href="#abstract" class="md-skip-link">Skip to content</a>

<!-- Top App Bar -->
<nav class="md-top-app-bar" id="topBar">
  <span class="md-top-app-bar__title">PLLM</span>
  <div class="md-top-app-bar__nav">
    <a href="/"><i class="fas fa-home"></i> Home</a>
    <a href="#abstract"><i class="fas fa-file-alt"></i> Abstract</a>
    <a href="#methodology"><i class="fas fa-cogs"></i> Methodology</a>
    <a href="#results"><i class="fas fa-chart-bar"></i> Results</a>
    <a href="#access"><i class="fas fa-download"></i> Paper</a>
  </div>
</nav>

<!-- Hero Section -->
<header class="md-hero">
  <h1 class="md-display-medium">Personalised LLM for Emotion-Aware Human-Robot and Human-Computer Interaction</h1>
  <p class="md-hero__subtitle">MDPI Sensors 2025 &bull; Ghamati, Dehkordi &amp; Zaraki &bull; University of Hertfordshire</p>
  <div class="md-hero__actions">
    <span class="md-publication-status md-publication-status--published"><i class="fas fa-check-circle"></i> Published &mdash; Open Access</span>
  </div>
</header>

<main class="md-container md-sp-32">

  <!-- About / Abstract -->
  <section class="md-section" id="abstract">
    <h2 class="md-headline-large md-mb-24">About This Work</h2>

    <div class="md-author-card md-mb-24">
      <div class="md-author-card__info">
        <div class="md-author-card__name">Khashayar Ghamati, Maryam Banitalebi Dehkordi, Abolfazl Zaraki</div>
        <div class="md-author-card__affiliation">University of Hertfordshire, UK</div>
        <div class="md-author-card__links">
          <a href="https://scholar.google.com/citations?user=zRG8t_oAAAAJ&hl=en" target="_blank" rel="noopener" title="Google Scholar"><i class="fas fa-graduation-cap"></i></a>
          <a href="https://orcid.org/0009-0002-6416-3127" target="_blank" rel="noopener" title="ORCID"><i class="fab fa-orcid"></i></a>
        </div>
      </div>
    </div>

    <!-- Publication Info -->
    <div class="md-card-outlined md-sp-24 md-mb-24" style="text-align:center;">
      <p class="md-title-large" style="color:var(--md-primary);">Published in MDPI Sensors 2025</p>
      <p class="md-body-large"><strong>DOI:</strong> <a href="https://doi.org/10.3390/s25072024" target="_blank" rel="noopener" style="color:var(--md-primary);">10.3390/s25072024</a></p>
      <span class="md-publication-status md-publication-status--published" style="margin-top:12px;"><i class="fab fa-creative-commons"></i> Open Access &mdash; CC BY 4.0</span>
    </div>

    <p class="md-body-large">
      <strong>Towards AI-Powered Applications: The Development of a Personalised LLM for HRI and HCI</strong> introduces a groundbreaking <b>Personalised Large Language Model (PLLM)</b> framework that achieves real-time adaptation to user emotions in both <b>Human-Robot Interaction (HRI)</b> and <b>Human-Computer Interaction (HCI)</b>. The PLLM integrates EEG-based emotion recognition with advanced dialogue generation, enabling context-aware and emotion-sensitive responses tailored to individual users.
    </p>

    <div class="md-highlight-box">
      <p class="md-highlight-box__title"><i class="fas fa-brain"></i> Innovation</p>
      <p>This is the first demonstration of real-time EEG-driven personalisation in LLM-based dialogue systems, opening new frontiers in neuroadaptive AI.</p>
    </div>
  </section>

  <!-- Figure 1 -->
  <figure class="md-figure">
    <img src="f1.jpg" alt="PLLM framework architecture showing EEG-driven emotion-adaptive AI dialogue system for human-robot interaction" loading="eager" width="800" height="600">
    <figcaption><strong>Figure 1:</strong> Overview of the PLLM framework architecture. EEG signals are processed in real-time for emotion classification, which then conditions the large language model to generate personalised, emotion-aware responses through a user-friendly Streamlit interface.</figcaption>
  </figure>

  <!-- Methodology -->
  <section class="md-section" id="methodology">
    <h2 class="md-headline-large md-mb-24">Framework Architecture &amp; Methodology</h2>
    <p class="md-body-large">
      The PLLM system represents a paradigm shift in adaptive AI, combining neuroscience with cutting-edge language models to create truly personalised interactions. Our framework consists of three integrated components working in seamless harmony:
    </p>

    <h3 class="md-title-large md-mb-16">Core Components</h3>
    <div class="md-method-grid">
      <div class="md-method-card">
        <div class="md-method-card__icon"><i class="fas fa-brain"></i></div>
        <div class="md-method-card__title">EEG-based Emotion Recognition</div>
        <div class="md-method-card__body">Real-time processing of neural signals using the NeuroSense dataset, employing advanced deep learning pipelines to classify emotional states with high accuracy.</div>
      </div>
      <div class="md-method-card">
        <div class="md-method-card__icon"><i class="fas fa-comment-dots"></i></div>
        <div class="md-method-card__title">Dynamic LLM Conditioning</div>
        <div class="md-method-card__body">Emotional state outputs directly influence prompt engineering, allowing the language model to adapt its tone, content, and interaction style based on the user's current affective state.</div>
      </div>
      <div class="md-method-card">
        <div class="md-method-card__icon"><i class="fas fa-desktop"></i></div>
        <div class="md-method-card__title">Interactive Deployment Platform</div>
        <div class="md-method-card__body">A sophisticated Streamlit application provides real-world accessibility, enabling researchers and end-users to experience emotion-adaptive AI in practice.</div>
      </div>
    </div>

    <div class="md-highlight-box md-mt-24">
      <p class="md-highlight-box__title"><i class="fas fa-cogs"></i> Technical Achievement</p>
      <p>The system processes EEG signals and generates contextually appropriate responses within milliseconds, demonstrating the feasibility of real-time neuroadaptive AI.</p>
    </div>
  </section>

  <!-- Figure 2 -->
  <figure class="md-figure">
    <img src="f2.jpg" alt="Real-time integration pipeline showing EEG emotion recognition feeding into personalised LLM dialogue generation" loading="lazy" width="800" height="600">
    <figcaption><strong>Figure 2:</strong> Real-time integration pipeline demonstrating the closed-loop system from EEG signal acquisition through emotion classification to adaptive dialogue generation, showcasing the seamless flow of neuroadaptive personalisation.</figcaption>
  </figure>

  <!-- Results -->
  <section class="md-section" id="results">
    <h2 class="md-headline-large md-mb-24">Experimental Results &amp; Validation</h2>
    <p class="md-body-large">
      Our comprehensive evaluation using the NeuroSense dataset demonstrates the effectiveness of emotion-driven personalisation in AI dialogue systems. The results establish new benchmarks for neuroadaptive human-computer interaction:
    </p>

    <h3 class="md-title-large md-mb-16">Key Findings</h3>
    <ul>
      <li><b>High-Accuracy Emotion Detection:</b> The EEG-based emotion recognition module achieves robust performance in real-time classification across multiple emotional states.</li>
      <li><b>Enhanced Dialogue Quality:</b> Emotion-conditioned prompts significantly improve the relevance, appropriateness, and user satisfaction compared to baseline language models.</li>
      <li><b>User Engagement Metrics:</b> Subjective evaluations reveal substantially increased engagement and perceived intelligence during emotion-adaptive interactions.</li>
      <li><b>Real-World Feasibility:</b> The Streamlit deployment demonstrates practical applicability for research and commercial applications.</li>
    </ul>

    <div class="md-highlight-box md-mt-24">
      <p class="md-highlight-box__title"><i class="fas fa-chart-line"></i> Impact</p>
      <p>This work establishes the foundational framework for next-generation neuroadaptive AI systems, with applications spanning healthcare, education, entertainment, and assistive technologies.</p>
    </div>
  </section>

  <!-- Scientific Contribution -->
  <section class="md-section">
    <h2 class="md-headline-large md-mb-24">Scientific Contribution &amp; Novelty</h2>
    <p class="md-body-large">
      Our research addresses a critical gap in adaptive AI systems by introducing the first practical framework for EEG-driven LLM personalisation. This work contributes to multiple domains:
    </p>

    <h3 class="md-title-large md-mb-16">Research Contributions</h3>
    <div class="md-method-grid">
      <div class="md-method-card">
        <div class="md-method-card__icon"><i class="fas fa-network-wired"></i></div>
        <div class="md-method-card__title">Neuroadaptive AI Architecture</div>
        <div class="md-method-card__body">Novel integration of brain-computer interfaces with large language models for real-time personalisation.</div>
      </div>
      <div class="md-method-card">
        <div class="md-method-card__icon"><i class="fas fa-heart"></i></div>
        <div class="md-method-card__title">Emotion-Aware Dialogue</div>
        <div class="md-method-card__body">Demonstration of how affective states can enhance AI communication quality and user experience.</div>
      </div>
      <div class="md-method-card">
        <div class="md-method-card__icon"><i class="fas fa-code-branch"></i></div>
        <div class="md-method-card__title">Open-Source Implementation</div>
        <div class="md-method-card__body">Reproducible research framework enabling widespread adoption and extension by the research community.</div>
      </div>
      <div class="md-method-card">
        <div class="md-method-card__icon"><i class="fas fa-expand-arrows-alt"></i></div>
        <div class="md-method-card__title">Cross-Domain Applications</div>
        <div class="md-method-card__body">Validated approach applicable to both HRI and HCI contexts, broadening the impact across multiple fields.</div>
      </div>
    </div>

    <div class="md-highlight-box md-mt-24">
      <p class="md-highlight-box__title"><i class="fas fa-lightbulb"></i> Future Implications</p>
      <p>This work paves the way for emotionally intelligent AI assistants, therapeutic robots, and adaptive learning systems that respond to users' mental states in real-time.</p>
    </div>
  </section>

  <!-- Open Science -->
  <section class="md-section">
    <h2 class="md-headline-large md-mb-24">Open Science &amp; Collaboration</h2>
    <p class="md-body-large">
      We are committed to advancing open, reproducible science in neuroadaptive AI. This research provides a foundation for collaborative development of more sophisticated emotion-aware systems and welcomes partnerships to extend these capabilities.
    </p>
    <div class="md-social-links" style="justify-content:center;">
      <a href="https://scholar.google.com/citations?user=zRG8t_oAAAAJ&hl=en" target="_blank" rel="noopener" title="Google Scholar">
        <i class="fas fa-graduation-cap"></i>
      </a>
      <a href="https://orcid.org/0009-0002-6416-3127" target="_blank" rel="noopener" title="ORCID">
        <i class="fab fa-orcid"></i>
      </a>
      <a href="https://www.mdpi.com/journal/sensors" target="_blank" rel="noopener" title="MDPI Sensors">
        <i class="fas fa-globe"></i>
      </a>
    </div>
  </section>

  <!-- Download / Access -->
  <section class="md-section" id="access">
    <h2 class="md-headline-large md-mb-24">Full Paper &amp; Code Access</h2>
    <div style="text-align:center;padding:24px 0;">
      <a href="https://www.mdpi.com/1424-8220/25/7/2024" target="_blank" rel="noopener" class="md-btn-filled" style="margin:8px;">
        <i class="fas fa-download"></i> Download Full Paper (Open Access)
      </a>
      <a href="#" class="md-btn-outlined" onclick="showCodeDialog(event)" style="margin:8px;">
        <i class="fas fa-code"></i> Access Source Code
      </a>
    </div>
    <p class="md-body-small" style="text-align:center;color:var(--md-on-surface-variant);margin-top:16px;">
      <i class="fas fa-info-circle"></i> The article is published under the <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank" rel="noopener" style="color:var(--md-primary);">CC BY 4.0 license</a>, ensuring open access for the research community.
    </p>
  </section>

</main>

<script>
  function showCodeDialog(event) {
    event.preventDefault();
    alert("To access the source code and datasets, please email us at: k.ghamati@herts.ac.uk\n\nWe're happy to share our implementation and support collaborative research!");
  }

  // Top app bar scroll shadow
  window.addEventListener('scroll', function() {
    var bar = document.getElementById('topBar');
    if (window.scrollY > 4) {
      bar.classList.add('md-scrolled');
    } else {
      bar.classList.remove('md-scrolled');
    }
  });
</script>

<footer style="background-color:var(--md-inverse-surface);color:var(--md-inverse-on-surface);text-align:center;padding:48px 24px;">
  <p>&copy; 2025 Khashayar Ghamati. All rights reserved.</p>
  <p class="md-body-small" style="opacity:0.8;margin-top:8px;">Advancing neuroadaptive AI for human-centered technology</p>
</footer>

</body>
</html>
