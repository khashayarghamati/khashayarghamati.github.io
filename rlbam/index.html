<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Khashayar Ghamati</title>

  <!-- Google Fonts -->
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap">

  <!-- External CSS for Icons -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">

  <style>
    body {
      font-family: 'Roboto', sans-serif;
      margin: 0;
      padding: 0;
      background-color: #f5f7fa;
      color: #333;
    }

    /* Toolbar Styling */
    .toolbar {
      background-color: #0077b6;
      padding: 1rem;
      position: sticky;
      top: 0;
      z-index: 1000;
      display: flex;
      justify-content: flex-start;
      box-shadow: 0 4px 10px rgba(0, 0, 0, 0.1);
    }

    .toolbar a {
      color: white;
      text-decoration: none;
      font-size: 1.125rem;
      font-weight: 400;
      margin-right: 20px;
      transition: color 0.3s;
    }

    .toolbar a:hover {
      color: #94d2bd;
    }

    header {
      background-color: #0077b6;
      padding: 2rem 0;
      text-align: center;
      color: white;
      box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
    }

    header h1 {
      font-size: 2.5rem;
      margin: 0;
      font-weight: 700;
    }

    .container {
      max-width: 1200px;
      margin: 2rem auto;
      padding: 0 20px;
    }

    section h2 {
      font-size: 2rem;
      color: #0077b6;
      text-align: center;
      margin-bottom: 1.5rem;
      font-weight: 700;
    }

    section p {
      font-size: 1.125rem;
      line-height: 1.6;
      text-align: justify;
      margin-bottom: 2rem;
    }

    /* Videos section */
    .videos {
      display: flex;
      justify-content: space-around;
      flex-wrap: wrap;
      gap: 1.5rem;
      margin-bottom: 3rem;
    }

    .videos iframe {
      flex: 1 1 45%;
      max-width: 45%;
      min-width: 300px;
      height: 315px;
    }

    /* Abstract section */
    h3 {
      color: #333;
      font-size: 1.5rem;
      margin-bottom: 1rem;
    }

    /* Download button */
    a.download-btn {
      display: inline-block;
      background-color: #0077b6;
      color: white;
      padding: 0.75rem 1.5rem;
      text-decoration: none;
      font-size: 1rem;
      border-radius: 5px;
      transition: background-color 0.3s;
      text-align: center;
      margin-top: 2rem;
      box-shadow: 0 4px 10px rgba(0, 0, 0, 0.1);
    }

    a.download-btn:hover {
      background-color: #0096c7;
    }

    /* Footer */
    footer {
      text-align: center;
      padding: 2rem 0;
      background-color: #023e8a;
      color: white;
      margin-top: 3rem;
      box-shadow: 0 -2px 10px rgba(0, 0, 0, 0.1);
    }

    /* Responsive design */
    @media (max-width: 768px) {
      header h1 {
        font-size: 2rem;
      }

      .videos iframe {
        max-width: 100%;
        height: auto;
      }

      section p {
        font-size: 1rem;
      }
    }
  </style>
</head>
<body>

<!-- Toolbar with Home Button -->
<div class="toolbar">
  <a href="/"><i class="fas fa-home"></i> Home</a>
</div>

<header>
  <h1>ARI humanoid robot imitates human gaze behaviour using
    reinforcement learning in real-world environments</h1>
</header>

<div class="container">
  <section id="rlbam">
    <h2>About the Paper</h2>
    <p>
      This paper presents a novel approach to enhance the social interaction capabilities of the ARI humanoid robot using reinforcement learning. We focus on enabling ARI to imitate human attention/gaze behaviour by identifying salient points in dynamic environments, employing the Zero-Shot Transfer technique combined with domain randomisation and generalisation. Our methodology employs the Proximal Policy Optimisation algorithm, training the reinforcement learning agent in a simulated environment to maximise robustness in real-world scenarios. We demonstrated the efficacy of our approach by deploying the trained agent on the ARI humanoid and validating its performance in human-robot interaction scenarios. The results indicated that ARI can successfully identify and respond to salient points, exhibiting human-like attention/gaze behaviours, which is an important step towards acceptability and efficiency in human-robot interactions. This research contributes to advancing the capabilities of social robots in dynamic and unpredictable environments, highlighting the potential of combining Zero-Shot Transfer with domain randomisation and generalisation for robust real-world applications.
    </p>

    <!-- Video Embeds -->
    <h3>Demonstration Videos</h3>
    <div class="videos">
      <iframe width="560" height="315" src="https://www.youtube.com/embed/your-video-id" title="YouTube video player" allowfullscreen></iframe>
      <iframe width="560" height="315" src="https://www.youtube.com/embed/another-video-id" title="YouTube video player" allowfullscreen></iframe>
    </div>

    <!-- Abstract -->


    <p>This research presents an innovative method to enhance the ARI humanoid robot's ability to engage in dynamic social interactions by imitating human gaze behaviours using reinforcement learning. The study tackles key challenges in deploying reinforcement learning agents in real-world environments, particularly the gap between simulation and real-world performance, known as the <strong>sim-to-real transfer problem</strong>. The method leverages <strong>Zero-Shot Transfer (ZST)</strong>, <strong>domain randomisation</strong>, and <strong>generalisation</strong> techniques, enabling ARI to seamlessly adapt from a simulated training environment to unpredictable, real-world scenarios without additional training.</p>

    <p>The reinforcement learning agent is trained using the <strong>Proximal Policy Optimisation (PPO)</strong> algorithm, integrated with an attention model that allows ARI to focus on salient points in its environment. By simulating various human activities, such as speaking and hand gestures, and considering proximity, the robot learns to prioritise individuals in a scene based on their social relevance. A <strong>Gaze Control System (GCS)</strong> is designed to guide the robot's gaze behaviour, rewarding it for identifying and attending to more socially important participants.</p>

    <h3>Challenges Addressed</h3>
    <ul>
      <li><strong>Sim-to-real transfer</strong>: Overcoming the discrepancies between simulated environments and the physical world by employing ZST and domain randomisation.</li>
      <li><strong>Sensor noise and variability</strong>: Although domain randomisation helped with environmental variability, sensor noise remains a significant challenge in real-world deployments.</li>
      <li><strong>Model robustness</strong>: Ensuring that the robot's attention model generalises well to unseen, dynamic states by creating diverse simulated scenarios during training.</li>
    </ul>

    <p>After training, the model was successfully deployed onto the ARI robot and tested in human-robot interaction scenarios. The results demonstrated that ARI can accurately mimic human-like gaze behaviours by identifying and responding to salient points in real time. The robotâ€™s ability to interact dynamically with human participants shows the potential for reinforcement learning to enhance social robots' capabilities in unpredictable, real-world environments.</p>

    <p>This research marks a significant advancement in human-robot interaction, addressing key challenges of transitioning reinforcement learning models from simulation to real-world deployment and providing insights into developing robust, adaptable social robots.</p>


    <!-- Download Paper -->
    <a href="#" download class="download-btn">Download Full Paper</a>
    <a href="#" download class="download-btn">Code</a>
  </section>
</div>

<footer>
  <p>&copy; 2024 Khashayar Ghamati Ghamsari. All rights reserved.</p>
</footer>

</body>
</html>
