<!DOCTYPE html>
<html lang="en-GB">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- DNS Prefetch and Preconnect for Performance -->
  <link rel="dns-prefetch" href="//fonts.googleapis.com">
  <link rel="dns-prefetch" href="//cdnjs.cloudflare.com">
  <link rel="preconnect" href="https://fonts.googleapis.com" crossorigin>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://cdnjs.cloudflare.com" crossorigin>

  <!-- SEO Meta Tags -->
  <meta name="description" content="CAPA-AI: continual adaptation framework for human-robot interaction using probabilistic novelty detection, reinforcement learning and VLMs. IEEE RO-MAN 2025.">
  <meta name="keywords" content="CAPA-AI, continual learning, continual adaptation, reinforcement learning, vision language model, artificial intelligence, IEEE RO-MAN 2025, machine learning, novelty detection, transfer learning, HRI, human-robot interaction, Khashayar Ghamati, robotics, open-world AI, ARI robot, probabilistic reasoning, cognitive AI, adaptive robotics, LLaVA, DeepSeek">
  <meta name="author" content="Khashayar Ghamati">
  <meta name="robots" content="index, follow">

  <!-- Open Graph -->
  <meta property="og:title" content="CAPA-AI: Novelty Detection for Continual Adaptation in HRI">
  <meta property="og:description" content="Continual learning framework achieving 89% novelty detection accuracy. Enables robots to adapt in real-time using probabilistic reasoning and transfer learning.">
  <meta property="og:image" content="https://ghamati.com/CAPA-AI/capa-ai.png">
  <meta property="og:type" content="article">
  <meta property="og:url" content="https://ghamati.com/CAPA-AI/">
  <meta property="og:site_name" content="Khashayar Ghamati - AI Research">
  <meta property="og:locale" content="en_GB">
  <meta property="article:author" content="Khashayar Ghamati">
  <meta property="article:published_time" content="2025-08-25">
  <meta property="article:section" content="Artificial Intelligence">
  <meta property="article:tag" content="continual learning">
  <meta property="article:tag" content="robotics">
  <meta property="article:tag" content="artificial intelligence">

  <!-- Twitter Card -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="CAPA-AI: Continual Learning for Robots | IEEE RO-MAN 2025">
  <meta name="twitter:description" content="Breakthrough in continual adaptation and reinforcement learning for robotics, presented at IEEE RO-MAN 2025 by Khashayar Ghamati.">
  <meta name="twitter:image" content="https://ghamati.com/CAPA-AI/capa-ai.png">
  <meta name="twitter:creator" content="@khashayarghamati">

  <link rel="canonical" href="https://ghamati.com/CAPA-AI/">

  <title>CAPA-AI: Novelty Detection for Continual Adaptation | IEEE RO-MAN 2025</title>

  <!-- Shared MD3 Design System -->
  <link rel="stylesheet" href="/css/material-design.css">

  <!-- Google Fonts -->
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Playfair+Display:wght@400;600;700&display=swap">

  <!-- Font Awesome Icons -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" integrity="sha512-Kc323vGBEqzTmouAECnVceyQqyqdsSiqLQISBL29aUW4U/M7pSPA/gEUZQqv1cwx4OnYxTxve5UMg5GT6L4JJg==" crossorigin="anonymous" referrerpolicy="no-referrer">

  <!-- Structured Data -->
  <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "ScholarlyArticle",
      "headline": "CAPA-AI: Cognitive Agentic AI - Probabilistic Novelty Detection for Continual Adaptation in HRI",
      "author": [
        {
          "@type": "Person",
          "name": "Khashayar Ghamati",
          "affiliation": {
            "@type": "Organization",
            "name": "University of Hertfordshire"
          },
          "url": "https://ghamati.com",
          "sameAs": [
            "https://scholar.google.com/citations?user=zRG8t_oAAAAJ&hl=en",
            "https://orcid.org/0009-0002-6416-3127"
          ]
        }
      ],
      "datePublished": "2025-08-25",
      "url": "https://ghamati.com/CAPA-AI/",
      "image": "https://ghamati.com/CAPA-AI/capa-ai.png",
      "inLanguage": "en",
      "publisher": {
        "@type": "Organization",
        "name": "IEEE RO-MAN Conference",
        "url": "https://ro-man2025.org/"
      },
      "about": [
        "continual learning",
        "continual adaptation",
        "reinforcement learning",
        "vision language model",
        "artificial intelligence",
        "machine learning",
        "robotics",
        "novelty detection",
        "transfer learning",
        "human-robot interaction"
      ],
      "description": "CAPA-AI integrates probabilistic novelty detection, transfer learning, and reinforcement learning for continual adaptation in HRI, leveraging vision-language models for robust open-world artificial intelligence. Presented at IEEE RO-MAN 2025.",
      "keywords": "CAPA-AI, continual learning, reinforcement learning, novelty detection, human-robot interaction, adaptive AI",
      "isAccessibleForFree": true,
      "creativeWorkStatus": "Published"
    }
  </script>

  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-HV1K905FF2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-HV1K905FF2');
  </script>

  <style>
    /* Page-specific: modal styles */
    .modal {
      display: none;
      position: fixed;
      z-index: 10000;
      left: 0;
      top: 0;
      width: 100%;
      height: 100%;
      background-color: rgba(0, 0, 0, 0.5);
      backdrop-filter: blur(5px);
    }
    .modal-content {
      background-color: var(--md-surface);
      margin: 15% auto;
      padding: 2rem;
      border-radius: var(--md-shape-lg);
      width: 90%;
      max-width: 500px;
      box-shadow: var(--md-elevation-3);
      animation: modalSlideIn 0.3s ease-out;
    }
    @keyframes modalSlideIn {
      from { opacity: 0; transform: translateY(-50px); }
      to { opacity: 1; transform: translateY(0); }
    }
    .modal-header {
      display: flex;
      justify-content: space-between;
      align-items: center;
      margin-bottom: 1rem;
      padding-bottom: 1rem;
      border-bottom: 2px solid var(--md-primary);
    }
    .modal-header h3 { margin: 0; color: var(--md-primary); }
    .modal-close {
      background: none;
      border: none;
      font-size: 1.5rem;
      cursor: pointer;
      color: var(--md-on-surface-variant);
    }
    .modal-body { margin-bottom: 1.5rem; line-height: 1.6; }
    .modal-footer { display: flex; justify-content: flex-end; gap: 1rem; }
  </style>
</head>
<body>

<a href="#abstract" class="md-skip-link">Skip to content</a>

<!-- Top App Bar -->
<nav class="md-top-app-bar" id="topBar">
  <span class="md-top-app-bar__title">CAPA-AI</span>
  <div class="md-top-app-bar__nav">
    <a href="/"><i class="fas fa-home"></i> Home</a>
    <a href="#abstract"><i class="fas fa-file-alt"></i> Abstract</a>
    <a href="#architecture"><i class="fas fa-cogs"></i> Architecture</a>
    <a href="#results"><i class="fas fa-chart-bar"></i> Results</a>
    <a href="#access"><i class="fas fa-download"></i> Paper</a>
  </div>
</nav>

<!-- Hero Section -->
<header class="md-hero">
  <h1 class="md-display-medium">Cognitive Agentic AI: Probabilistic Novelty Detection for Continual Adaptation in HRI</h1>
  <p class="md-hero__subtitle">IEEE RO-MAN 2025 &bull; Khashayar Ghamati &bull; University of Hertfordshire</p>
  <div class="md-hero__actions">
    <span class="md-publication-status md-publication-status--published"><i class="fas fa-check-circle"></i> Published</span>
  </div>
</header>

<main class="md-container md-sp-32">

  <!-- About / Abstract -->
  <section class="md-section" id="abstract">
    <h2 class="md-headline-large md-mb-24">About the Paper</h2>

    <div class="md-author-card md-mb-24">
      <div class="md-author-card__info">
        <div class="md-author-card__name">Khashayar Ghamati</div>
        <div class="md-author-card__affiliation">University of Hertfordshire, UK</div>
        <div class="md-author-card__links">
          <a href="https://scholar.google.com/citations?user=zRG8t_oAAAAJ&hl=en" target="_blank" rel="noopener" title="Google Scholar"><i class="fas fa-graduation-cap"></i></a>
          <a href="https://orcid.org/0009-0002-6416-3127" target="_blank" rel="noopener" title="ORCID"><i class="fab fa-orcid"></i></a>
        </div>
      </div>
    </div>

    <p class="md-body-large">
      Adapting to novel tasks in human-robot interaction (HRI) is crucial for long-term autonomy, yet remains a major challenge for autonomous agents deployed in unpredictable open-world settings. This paper introduces CAPA-AI, a novel framework that integrates probabilistic novelty detection with continual post-deployment adaptation achieved via transfer learning to address this challenge. The framework's novelty detection component employs conditional probability and the Jaccard Index to identify unfamiliar tasks by quantifying their deviation from the agent's knowledge base of previously learned tasks. Upon detecting a novel task, the agent utilises transfer learning to repurpose prior knowledge and update its models without retraining from scratch. We detail the design of CAPA-AI, including an isolated learning phase for initial skill acquisition and the construction of a dynamic knowledge base. The complete system was deployed on a social robot in real-world HRI scenarios to evaluate its performance. Experimental results demonstrated that the agent accurately detects novel tasks and adapts to them, achieving adaptation and novelty detection accuracies of 80% and 89%, respectively. These findings underscore the efficacy of the proposed approach and highlight a significant step towards robust open-world deployment of AI agents in HRI, where continuous adaptation and the safe handling of unforeseen tasks are essential.
    </p>

    <div class="md-highlight-box">
      <p class="md-highlight-box__title"><i class="fas fa-lightbulb"></i> Did you know?</p>
      <p>Most deployed AI agents freeze after initial training -- they cannot tell when the world changes. CAPA-AI can!</p>
    </div>
  </section>

  <!-- Figure 1 -->
  <figure class="md-figure">
    <img src="capa-ai.png" alt="CAPA-AI continual learning agentic AI architecture for reinforcement learning and HRI" loading="eager" width="800" height="600">
    <figcaption><strong>Figure 1:</strong> Overview of the CAPA-AI architecture. A reinforcement learning (RL) agent is pre-trained in isolation, while a knowledge base stores task-specific information for novelty detection. When a novel task is detected during real-world operation, the agent leverages transfer learning or its own exploration to adapt, updating both its policy and knowledge base.</figcaption>
  </figure>

  <!-- Motivation -->
  <section class="md-section">
    <h2 class="md-headline-large md-mb-24">Continual Learning &amp; Adaptation: Motivation</h2>
    <p class="md-body-large">
      Autonomous robots operating in dynamic, human-centred environments constantly face unpredictability -- no dataset or pre-training can prepare them for everything. Traditional AI systems are prone to <b>catastrophic forgetting</b> if retrained, or simply ignore novel tasks, which risks safety and erodes user trust.
    </p>
    <p class="md-body-large">
      <b>CAPA-AI</b> addresses this by equipping the robot with two essential abilities:
    </p>
    <ul class="md-highlight-box">
      <li><b>Novelty detection:</b> Accurately identifies when an observed task or situation has not been encountered before.</li>
      <li><b>Continual adaptation:</b> Upon detecting novelty, the robot can re-use related prior knowledge (via transfer learning) to adapt, or gather new experience as needed -- all without full retraining or human-in-the-loop supervision.</li>
    </ul>
    <div class="md-highlight-box md-mt-24">
      <p class="md-highlight-box__title"><i class="fas fa-info-circle"></i> Open-World Autonomy</p>
      <p>This paves the way for true open-world autonomy -- robots that can self-improve as the world changes.</p>
    </div>
  </section>

  <!-- Architecture -->
  <section class="md-section" id="architecture">
    <h2 class="md-headline-large md-mb-24">How the CAPA-AI Architecture Works</h2>
    <h3 class="md-title-large md-mb-16">Reinforcement Learning &amp; Vision Language Models in CAPA-AI</h3>

    <div class="md-method-grid">
      <div class="md-method-card">
        <div class="md-method-card__icon"><i class="fas fa-brain"></i></div>
        <div class="md-method-card__title">Isolated Learning Phase</div>
        <div class="md-method-card__body">The RL agent is initially trained on a set of known tasks (e.g., using the RHM dataset). Task-specific experiences and environmental keywords are stored in an Agent Knowledge Base (AKB).</div>
      </div>
      <div class="md-method-card">
        <div class="md-method-card__icon"><i class="fas fa-eye"></i></div>
        <div class="md-method-card__title">Novelty Detection Module</div>
        <div class="md-method-card__body">During real-world operation, incoming sensor data (video frames) are processed using vision-language models (e.g., LLaVA) and contextual keywords are extracted (e.g., via DeepSeek).</div>
      </div>
      <div class="md-method-card">
        <div class="md-method-card__icon"><i class="fas fa-calculator"></i></div>
        <div class="md-method-card__title">Probabilistic Novelty Detection</div>
        <div class="md-method-card__body">New keywords are compared with the AKB using conditional probability and the Jaccard Index, computing a posterior probability of task similarity. High similarity (&gt;90%) uses the pre-trained model; partial similarity (60-89%) triggers transfer learning; genuinely novel cases (&lt;60%) trigger exploration.</div>
      </div>
      <div class="md-method-card">
        <div class="md-method-card__icon"><i class="fas fa-exchange-alt"></i></div>
        <div class="md-method-card__title">Transfer Learning</div>
        <div class="md-method-card__body">The agent updates its RL policy using strategies from similar tasks, rapidly adapting to the new task and updating its AKB.</div>
      </div>
    </div>

    <div class="md-highlight-box">
      <p class="md-highlight-box__title"><i class="fas fa-robot"></i> Innovation</p>
      <p>CAPA-AI uniquely combines <b>probabilistic reasoning, memory, transfer learning,</b> and <b>real-time feedback</b> to enable seamless, explainable adaptation in unpredictable settings.</p>
    </div>
  </section>

  <!-- Video Section -->
  <section class="md-section">
    <h2 class="md-headline-large md-mb-24">CAPA-AI Framework Explained</h2>
    <p class="md-body-large">
      Watch this comprehensive video explanation of the CAPA-AI framework architecture. Learn how probabilistic novelty detection using conditional probability and the Jaccard Index enables robots to identify unfamiliar tasks, and how transfer learning allows autonomous agents to adapt in real-time without retraining. The video demonstrates the complete system deployment on the ARI social robot in real-world human-robot interaction scenarios.
    </p>
    <div class="md-card-outlined md-sp-24 md-mt-24" style="overflow:hidden;border-radius:var(--md-shape-md);">
      <div style="position:relative;padding-bottom:56.25%;height:0;overflow:hidden;">
        <iframe src="https://www.youtube.com/embed/pTxR_r9Mo2c"
                style="position:absolute;top:0;left:0;width:100%;height:100%;border:0;"
                allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                allowfullscreen
                title="CAPA-AI: Cognitive Agentic AI - Probabilistic Novelty Detection for Continual Adaptation in HRI"
                loading="lazy">
        </iframe>
      </div>
      <p class="md-body-small" style="padding:16px 0 0;color:var(--md-on-surface-variant);text-align:center;font-style:italic;"><strong>Video:</strong> Detailed explanation of CAPA-AI framework - how probabilistic novelty detection and transfer learning enable continual adaptation in human-robot interaction.</p>
    </div>
  </section>

  <!-- VideoObject Schema -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "VideoObject",
    "name": "CAPA-AI: Cognitive Agentic AI - Probabilistic Novelty Detection for Continual Adaptation in HRI",
    "description": "Comprehensive explanation of the CAPA-AI framework for continual learning and adaptation in robotics. Covers probabilistic novelty detection using conditional probability, transfer learning for task adaptation, and real-world deployment on the ARI humanoid robot for human-robot interaction.",
    "thumbnailUrl": "https://img.youtube.com/vi/pTxR_r9Mo2c/maxresdefault.jpg",
    "uploadDate": "2025-01-20",
    "duration": "PT10M",
    "contentUrl": "https://www.youtube.com/watch?v=pTxR_r9Mo2c",
    "embedUrl": "https://www.youtube.com/embed/pTxR_r9Mo2c",
    "publisher": {
      "@type": "Person",
      "name": "Khashayar Ghamati",
      "url": "https://ghamati.com"
    },
    "keywords": "CAPA-AI, continual learning, novelty detection, reinforcement learning, human-robot interaction, transfer learning, probabilistic AI, adaptive robotics, agentic AI, machine learning",
    "inLanguage": "en",
    "isFamilyFriendly": true
  }
  </script>

  <!-- Figure 2 -->
  <figure class="md-figure">
    <img src="novelty-detection.png" alt="Novelty detection results using probabilistic methods and Jaccard Index in continual learning for reinforcement learning agent in HRI" loading="lazy" width="700" height="500">
    <figcaption><strong>Figure 2:</strong> Example result of the novelty detection pipeline. Posterior probabilities and the Jaccard Index are used to quantify how closely new observations match known tasks (here, the "Drinking" activity). This enables reliable detection and triggers adaptation only when truly necessary.</figcaption>
  </figure>

  <!-- Results -->
  <section class="md-section" id="results">
    <h2 class="md-headline-large md-mb-24">Step-by-Step Adaptation and Results</h2>
    <h3 class="md-title-large md-mb-16">Presented at IEEE RO-MAN 2025 Conference</h3>
    <ul>
      <li><b>Pre-training:</b> CAPA-AI is pre-trained using the RHM dataset on 14 daily human activities. For each, the agent stores both policy knowledge and a vocabulary of environmental/contextual keywords.</li>
      <li><b>Simulation Evaluation:</b> The framework is tested on the EatSense and Polar datasets (which contain new, partially overlapping tasks). CAPA-AI detects and adapts to novel activities, transferring knowledge from the most similar tasks.</li>
      <li><b>Real-World Deployment:</b> CAPA-AI is implemented on the ARI humanoid robot, interacting with users performing both familiar and unfamiliar tasks in real environments.</li>
    </ul>

    <figure class="md-figure">
      <img src="eval-pipeline.png" alt="Evaluation workflow for CAPA-AI agent with simulation and real-world continual adaptation, leveraging reinforcement learning and transfer learning in machine learning" loading="lazy" width="750" height="550">
      <figcaption><strong>Figure 3:</strong> Evaluation workflow: CAPA-AI is pre-trained, then deployed in both simulated (EatSense/Polar) and real-world HRI scenarios, where it processes sensory data and adapts in real time.</figcaption>
    </figure>

    <ul>
      <li><b>Sample Scenario:</b> In one real-world test, the robot observes the action "using tissue" -- not seen during training. CAPA-AI's ND module classifies this as novel but similar to "cleaning," so transfer learning is triggered. The agent updates its behaviour, improving performance in subsequent encounters.</li>
      <li><b>Accuracy:</b> CAPA-AI achieves <b>89% novelty detection accuracy</b> and <b>80% adaptation accuracy</b> in real-world tests. The approach is robust to sensor noise and ambiguous activities.</li>
    </ul>

    <div class="md-stat-row md-mt-24">
      <div class="md-stat-badge">
        <div class="md-stat-badge__value">89%</div>
        <div class="md-stat-badge__label">Novelty Detection</div>
      </div>
      <div class="md-stat-badge">
        <div class="md-stat-badge__value">80%</div>
        <div class="md-stat-badge__label">Adaptation Accuracy</div>
      </div>
      <div class="md-stat-badge">
        <div class="md-stat-badge__value">14</div>
        <div class="md-stat-badge__label">Pre-trained Activities</div>
      </div>
    </div>
  </section>

  <!-- Figure 4: Real-world results -->
  <figure class="md-figure">
    <img src="R1.png" alt="CAPA-AI real-world test: drinking task correctly recognised by continual learning agent using reinforcement learning and vision language models in human-robot interaction" loading="lazy" width="400" height="300">
    <p class="md-figure__caption"><strong>a)</strong> Task: Drinking, CAPA-AI Decision: Drinking</p>
    <img src="R2.png" alt="CAPA-AI real-world novelty detection: using tissue task identified as novel and mapped to cleaning using transfer learning and contextual adaptation in HRI" loading="lazy" width="400" height="300">
    <p class="md-figure__caption"><strong>b)</strong> Task: Using Tissue, CAPA-AI Decision: Novelty, Similar Task: Cleaning</p>
    <img src="R3.png" alt="CAPA-AI agent adaptation: laying down task detected as novel but similar to sitting down, demonstrating explainable continual adaptation in real-world human-robot interaction" loading="lazy" width="400" height="300">
    <p class="md-figure__caption"><strong>c)</strong> Task: Laying, CAPA-AI Decision: Novelty, Similar Task: Sitting Down</p>
    <figcaption>
      <strong>Figure 4:</strong> CAPA-AI real-world decisions: (a) "Drinking" correctly identified as familiar; (b) "Using tissue" detected as a novel action and mapped to "cleaning"; (c) "Lying down" treated as novel but similar to "sitting down," showing CAPA-AI's fine-grained, explainable adaptation.
    </figcaption>
  </figure>

  <!-- Why It Matters -->
  <section class="md-section">
    <h2 class="md-headline-large md-mb-24">Why It Matters</h2>
    <p class="md-body-large">
      <b>CAPA-AI</b> advances the state of the art in robot autonomy and trust by:
    </p>
    <ul>
      <li>Enabling <b>safe, continual adaptation</b> in dynamic environments -- no more "frozen" agents!</li>
      <li>Providing <b>probabilistic, explainable decisions</b> on when to adapt and what to adapt from</li>
      <li>Reducing risk of catastrophic forgetting or inappropriate generalisation</li>
      <li>Improving HRI by making robots more reliable, responsive, and aware of their own limitations</li>
    </ul>
    <div class="md-highlight-box md-mt-24">
      <p class="md-highlight-box__title"><i class="fas fa-hands-helping"></i> Impact</p>
      <p>This approach benefits social robotics, assistive technologies, service robots, and any AI deployed "in the wild."</p>
    </div>
  </section>

  <!-- Open Science -->
  <section class="md-section">
    <h2 class="md-headline-large md-mb-24">Open Science &amp; Collaboration</h2>
    <p class="md-body-large">
      Interested in collaborating, adapting, or extending CAPA-AI? We support open, reproducible science and welcome new partnerships to push forward robust and adaptive agentic AI.
    </p>
    <div class="md-social-links" style="justify-content:center;">
      <a href="https://scholar.google.com/citations?user=zRG8t_oAAAAJ&hl=en" target="_blank" rel="noopener" title="Google Scholar">
        <i class="fas fa-graduation-cap"></i>
      </a>
      <a href="https://orcid.org/0009-0002-6416-3127" target="_blank" rel="noopener" title="ORCID">
        <i class="fab fa-orcid"></i>
      </a>
    </div>
  </section>

  <!-- Download / Access -->
  <section class="md-section" id="access">
    <h2 class="md-headline-large md-mb-24">Full Paper &amp; Code</h2>
    <div style="text-align:center;padding:24px 0;">
      <a href="https://doi.org/10.1109/RO-MAN63969.2025.11217818" class="md-btn-filled" target="_blank" rel="noopener noreferrer" style="margin:8px;">
        <i class="fas fa-download"></i> Download Full Paper
      </a>
      <a href="#" class="md-btn-outlined" onclick="showCodeDialog(event)" style="margin:8px;">
        <i class="fas fa-code"></i> View Code
      </a>
    </div>
    <p class="md-body-small" style="text-align:center;color:var(--md-on-surface-variant);margin-top:16px;">
      <i class="fas fa-info-circle"></i> Research outputs will be available following conference presentation and publication.
    </p>
  </section>

</main>

<!-- Modal Dialogs -->
<div id="paperModal" class="modal">
  <div class="modal-content">
    <div class="modal-header">
      <h3><i class="fas fa-file-alt"></i> Full Paper Access</h3>
      <button class="modal-close" onclick="closeModal('paperModal')">&times;</button>
    </div>
    <div class="modal-body">
      <p>This paper will be available in the proceedings of <strong>IEEE RO-MAN 2025</strong> after the conference takes place in August 2025.</p>
      <p>For early access or collaboration inquiries, please contact:</p>
      <p><strong><i class="fas fa-envelope"></i> k.ghamati@herts.ac.uk</strong></p>
    </div>
    <div class="modal-footer">
      <button class="md-btn-outlined" onclick="closeModal('paperModal')">Close</button>
      <button class="md-btn-filled" onclick="copyEmail()">Copy Email</button>
    </div>
  </div>
</div>

<div id="codeModal" class="modal">
  <div class="modal-content">
    <div class="modal-header">
      <h3><i class="fas fa-code"></i> Source Code Access</h3>
      <button class="modal-close" onclick="closeModal('codeModal')">&times;</button>
    </div>
    <div class="modal-body">
      <p>To access the source code, datasets, and experimental materials for CAPA-AI, please contact our research team:</p>
      <p><strong><i class="fas fa-envelope"></i> k.ghamati@herts.ac.uk</strong></p>
      <p><i class="fas fa-info-circle"></i> We're committed to open science and collaborative research!</p>
    </div>
    <div class="modal-footer">
      <button class="md-btn-outlined" onclick="closeModal('codeModal')">Close</button>
      <button class="md-btn-filled" onclick="copyEmail()">Copy Email</button>
    </div>
  </div>
</div>

<script>
  function showPaperDialog(event) {
    event.preventDefault();
    document.getElementById('paperModal').style.display = 'block';
  }

  function showCodeDialog(event) {
    event.preventDefault();
    document.getElementById('codeModal').style.display = 'block';
  }

  function closeModal(modalId) {
    document.getElementById(modalId).style.display = 'none';
  }

  function copyEmail() {
    navigator.clipboard.writeText('k.ghamati@herts.ac.uk').then(function() {
      var btn = event.target;
      var originalText = btn.innerHTML;
      btn.innerHTML = '<i class="fas fa-check"></i> Copied!';
      setTimeout(function() {
        btn.innerHTML = originalText;
      }, 2000);
    });
  }

  window.onclick = function(event) {
    if (event.target.classList.contains('modal')) {
      event.target.style.display = 'none';
    }
  }

  document.addEventListener('keydown', function(event) {
    if (event.key === 'Escape') {
      var modals = document.querySelectorAll('.modal');
      modals.forEach(function(modal) {
        modal.style.display = 'none';
      });
    }
  });

  // Top app bar scroll shadow
  window.addEventListener('scroll', function() {
    var bar = document.getElementById('topBar');
    if (window.scrollY > 4) {
      bar.classList.add('md-scrolled');
    } else {
      bar.classList.remove('md-scrolled');
    }
  });
</script>

<footer style="background-color:var(--md-inverse-surface);color:var(--md-inverse-on-surface);text-align:center;padding:48px 24px;">
  <p>&copy; 2025 Khashayar Ghamati. All rights reserved.</p>
  <p class="md-body-small" style="opacity:0.8;margin-top:8px;">Advancing AI research for a better future</p>
</footer>

</body>
</html>
