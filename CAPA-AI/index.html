<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <!-- DNS Prefetch and Preconnect for Performance -->
  <link rel="dns-prefetch" href="//fonts.googleapis.com">
  <link rel="dns-prefetch" href="//cdnjs.cloudflare.com">
  <link rel="preconnect" href="https://fonts.googleapis.com" crossorigin>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://cdnjs.cloudflare.com" crossorigin>
  
  <!-- Enhanced SEO Meta Tags -->
  <meta name="description" content="CAPA-AI: Revolutionary continual adaptation framework for human-robot interaction using probabilistic novelty detection, reinforcement learning, and vision-language models. Presented at IEEE RO-MAN 2025 with 89% novelty detection accuracy.">
  <meta name="keywords" content="CAPA-AI, continual learning, continual adaptation, reinforcement learning, vision language model, artificial intelligence, IEEE RO-MAN 2025, machine learning, novelty detection, transfer learning, HRI, human-robot interaction, Khashayar Ghamati, robotics, open-world AI, ARI robot, probabilistic reasoning, cognitive AI, adaptive robotics, LLaVA, DeepSeek">
  <meta name="author" content="Khashayar Ghamati">
  <meta name="robots" content="index, follow">

  <!-- Open Graph for social and richer search results -->
  <meta property="og:title" content="CAPA-AI: Continual Adaptation & Novelty Detection in Human-Robot Interaction | IEEE RO-MAN 2025">
  <meta property="og:description" content="Breakthrough continual learning framework achieving 89% novelty detection accuracy. CAPA-AI enables robots to adapt in real-time using probabilistic reasoning and transfer learning.">
  <meta property="og:image" content="https://ghamati.com/CAPA-AI/capa-ai.png">
  <meta property="og:type" content="article">
  <meta property="og:url" content="https://ghamati.com/CAPA-AI/">
  <meta property="og:site_name" content="Khashayar Ghamati - AI Research">
  <meta property="article:author" content="Khashayar Ghamati">
  <meta property="article:published_time" content="2025-08-25">
  <meta property="article:section" content="Artificial Intelligence">
  <meta property="article:tag" content="continual learning">
  <meta property="article:tag" content="robotics">
  <meta property="article:tag" content="artificial intelligence">

  <!-- Twitter Card -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="CAPA-AI: Continual Learning & Adaptation for Robots | IEEE RO-MAN 2025">
  <meta name="twitter:description" content="Discover a breakthrough in continual adaptation and reinforcement learning for robotics, presented at IEEE RO-MAN 2025 by Khashayar Ghamati.">
  <meta name="twitter:image" content="https://ghamati.com/CAPA-AI/capa-ai.png">
  <meta name="twitter:creator" content="@khashayarghamati">

  <link rel="canonical" href="https://ghamati.com/CAPA-AI/">

  <title>CAPA-AI: Continual Learning & Novelty Detection for Human-Robot Interaction | IEEE RO-MAN 2025</title>

  <!-- Google Fonts -->
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Playfair+Display:wght@400;600;700&display=swap">

  <!-- External CSS for Icons -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" integrity="sha512-Kc323vGBEqzTmouAECnVceyQqyqdsSiqLQISBL29aUW4U/M7pSPA/gEUZQqv1cwx4OnYxTxve5UMg5GT6L4JJg==" crossorigin="anonymous" referrerpolicy="no-referrer">

  <!-- Enhanced Structured Data -->
  <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "ScholarlyArticle",
      "headline": "CAPA-AI: Cognitive Agentic AI - Probabilistic Novelty Detection for Continual Adaptation in HRI",
      "author": [
        {
          "@type": "Person",
          "name": "Khashayar Ghamati",
          "affiliation": {
            "@type": "Organization",
            "name": "University of Hertfordshire"
          },
          "url": "https://ghamati.com",
          "sameAs": [
            "https://scholar.google.com/citations?user=zRG8t_oAAAAJ&hl=en",
            "https://orcid.org/0009-0002-6416-3127"
          ]
        }
      ],
      "datePublished": "2025-08-25",
      "url": "https://ghamati.com/CAPA-AI/",
      "image": "https://ghamati.com/CAPA-AI/capa-ai.png",
      "inLanguage": "en",
      "publisher": {
        "@type": "Organization",
        "name": "IEEE RO-MAN Conference",
        "url": "https://ro-man2025.org/"
      },
      "about": [
        "continual learning",
        "continual adaptation",
        "reinforcement learning",
        "vision language model",
        "artificial intelligence",
        "machine learning",
        "robotics",
        "novelty detection",
        "transfer learning",
        "human-robot interaction"
      ],
      "description": "CAPA-AI integrates probabilistic novelty detection, transfer learning, and reinforcement learning for continual adaptation in HRI, leveraging vision-language models for robust open-world artificial intelligence. Presented at IEEE RO-MAN 2025.",
      "keywords": "CAPA-AI, continual learning, reinforcement learning, novelty detection, human-robot interaction, adaptive AI",
      "isAccessibleForFree": true,
      "creativeWorkStatus": "Published"
    }
  </script>

  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-HV1K905FF2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-HV1K905FF2');
  </script>

  <style>
    :root {
      /* Modern Professional Palette */
      --primary-blue: #0f172a;
      --primary-blue-light: #1e293b;
      --secondary-blue: #3b82f6;
      --accent-emerald: #10b981;
      --accent-purple: #8b5cf6;
      --accent-orange: #f59e0b;
      
      /* Modern Neutrals */
      --bg-primary: #ffffff;
      --bg-secondary: #f8fafc;
      --bg-accent: #f1f5f9;
      --text-primary: #0f172a;
      --text-secondary: #475569;
      --text-muted: #64748b;
      --border-light: #e2e8f0;
      --border-medium: #cbd5e1;
      
      /* Modern Gradients */
      --gradient-primary: linear-gradient(135deg, var(--primary-blue) 0%, var(--primary-blue-light) 100%);
      --gradient-accent: linear-gradient(135deg, var(--secondary-blue) 0%, var(--accent-emerald) 100%);
      --gradient-hero: linear-gradient(135deg, var(--primary-blue) 0%, var(--secondary-blue) 50%, var(--accent-emerald) 100%);
      
      /* Typography */
      --font-heading: 'Playfair Display', serif;
      --font-body: 'Inter', sans-serif;
      
      /* Modern Shadows */
      --shadow-sm: 0 1px 2px 0 rgba(0, 0, 0, 0.05);
      --shadow-md: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
      --shadow-lg: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
      --shadow-xl: 0 20px 25px -5px rgba(0, 0, 0, 0.1), 0 10px 10px -5px rgba(0, 0, 0, 0.04);
      
      /* Spacing System */
      --space-xs: 0.5rem;
      --space-sm: 1rem;
      --space-md: 1.5rem;
      --space-lg: 2rem;
      --space-xl: 3rem;
      --space-2xl: 4rem;
    }

    *, *::before, *::after {
      box-sizing: border-box;
    }
    
    body {
      font-family: var(--font-body);
      margin: 0;
      padding: 0;
      background: var(--bg-secondary);
      color: var(--text-primary);
      line-height: 1.7;
      font-size: 16px;
    }

    /* Toolbar Styling */
    .toolbar {
      background: var(--gradient-primary);
      padding: 1rem 0;
      position: sticky;
      top: 0;
      z-index: 1000;
      box-shadow: var(--shadow-md);
      backdrop-filter: blur(10px);
    }

    .toolbar .container {
      display: flex;
      justify-content: flex-start;
      align-items: center;
      margin: 0;
      padding: 0 2rem;
    }

    .toolbar a {
      color: white;
      text-decoration: none;
      font-size: 1rem;
      font-weight: 500;
      padding: 0.5rem 1rem;
      border-radius: 25px;
      transition: all 0.3s ease;
      display: flex;
      align-items: center;
      gap: 0.5rem;
    }

    .toolbar a:hover {
      background: rgba(255, 255, 255, 0.2);
      transform: translateY(-2px);
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
    }

    /* Header Styling */
    header {
      background: var(--gradient-hero);
      padding: 4rem 0;
      text-align: center;
      color: white;
      position: relative;
      overflow: hidden;
    }

    header::before {
      content: '';
      position: absolute;
      top: 0;
      left: 0;
      right: 0;
      bottom: 0;
      background: url('data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1000 300"><path fill="%23ffffff" fill-opacity="0.1" d="M0,96L48,112C96,128,192,160,288,170.7C384,181,480,171,576,154.7C672,139,768,117,864,117.3C960,117,1056,139,1152,149.3C1248,160,1344,160,1392,160L1440,160L1440,320L1392,320C1344,320,1248,320,1152,320C1056,320,960,320,864,320C768,320,672,320,576,320C480,320,384,320,288,320C192,320,96,320,48,320L0,320Z"/></svg>') repeat-x bottom;
      background-size: 1440px 160px;
    }

    header h1 {
      font-family: var(--font-heading);
      font-size: clamp(2rem, 5vw, 3.5rem);
      margin: 0;
      font-weight: 700;
      text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.1);
      line-height: 1.2;
      max-width: 1200px;
      margin: 0 auto;
      padding: 0 2rem;
    }

    /* Container */
    .container {
      max-width: 1200px;
      margin: 0 auto;
      padding: 0 2rem;
    }

    /* Main Content */
    main {
      padding: 4rem 0;
    }

    /* Section Styling */
    section {
      background: var(--bg-primary);
      margin: 3rem 0;
      padding: 3rem;
      border-radius: 20px;
      box-shadow: var(--shadow-soft);
      position: relative;
      overflow: hidden;
    }

    section h2 {
      font-family: var(--font-heading);
      font-size: 2.5rem;
      color: var(--primary-warm);
      text-align: center;
      margin: 0 0 2rem 0;
      font-weight: 600;
      position: relative;
    }

    section h2::after {
      content: '';
      display: block;
      width: 80px;
      height: 4px;
      background: var(--gradient-gold);
      margin: 1rem auto;
      border-radius: 2px;
    }

    section h3 {
      font-family: var(--font-heading);
      color: var(--text-primary);
      font-size: 1.8rem;
      margin: 2rem 0 1rem 0;
      font-weight: 600;
    }

    section p {
      font-size: 1.1rem;
      line-height: 1.8;
      color: var(--text-secondary);
      margin-bottom: 1.5rem;
      text-align: left;
    }

    /* Enhanced Lists */
    ul {
      list-style: none;
      padding: 0;
    }

    ul li {
      position: relative;
      padding: 0.8rem 0 0.8rem 2rem;
      margin: 0.5rem 0;
      font-size: 1.1rem;
      line-height: 1.7;
      color: var(--text-secondary);
    }

    ul li::before {
      content: '→';
      position: absolute;
      left: 0;
      color: var(--primary-warm);
      font-weight: bold;
      font-size: 1.2rem;
    }

    /* Figure Styling */
    .figure {
      text-align: center;
      margin: 3rem 0;
      background: var(--bg-primary);
      padding: 2rem;
      border-radius: 15px;
      box-shadow: var(--shadow-soft);
    }

    .figure img {
      max-width: 100%;
      height: auto;
      border-radius: 12px;
      box-shadow: var(--shadow-medium);
      transition: transform 0.3s ease;
    }

    .figure img:hover {
      transform: scale(1.02);
    }

    .figure p {
      margin-top: 1.5rem;
      font-style: italic;
      color: var(--text-muted);
      font-size: 0.95rem;
      line-height: 1.6;
    }

    .figure-large img {
      max-width: 85%;
    }

    /* Highlight Box */
    .highlight {
      background: linear-gradient(135deg, var(--accent-warm) 0%, var(--accent-gold) 100%);
      color: white;
      padding: 2rem;
      border-radius: 15px;
      margin: 2rem 0;
      box-shadow: var(--shadow-medium);
    }

    .highlight .fas {
      font-size: 1.2rem;
      margin-right: 0.5rem;
    }

    /* Download Buttons */
    .download-section {
      text-align: center;
      padding: 3rem 0;
    }

    .download-btn {
      display: inline-block;
      background: var(--gradient-accent);
      color: white;
      padding: 1rem 2rem;
      margin: 0.5rem;
      text-decoration: none;
      font-size: 1.1rem;
      font-weight: 500;
      border-radius: 50px;
      transition: all 0.3s ease;
      box-shadow: var(--shadow-lg);
      position: relative;
      overflow: hidden;
    }

    .download-btn::before {
      content: '';
      position: absolute;
      top: 0;
      left: -100%;
      width: 100%;
      height: 100%;
      background: linear-gradient(90deg, transparent, rgba(255, 255, 255, 0.2), transparent);
      transition: left 0.5s;
    }

    .download-btn:hover {
      transform: translateY(-3px);
      box-shadow: var(--shadow-xl);
    }

    .download-btn:hover::before {
      left: 100%;
    }

    /* Footer */
    footer {
      background: var(--gradient-primary);
      color: white;
      text-align: center;
      padding: 3rem 0;
      margin-top: 4rem;
    }

    /* Social Links */
    .social-links {
      display: flex;
      justify-content: center;
      gap: 1rem;
      margin: 2rem 0;
    }

    .social-links a {
      color: var(--primary-warm);
      font-size: 1.5rem;
      transition: all 0.3s ease;
    }

    .social-links a:hover {
      color: var(--accent-gold);
      transform: translateY(-2px);
    }

    /* Responsive Design */
    @media (max-width: 768px) {
      .container {
        padding: 0 1rem;
      }
      
      section {
        padding: 2rem 1.5rem;
        margin: 2rem 0;
      }
      
      header {
        padding: 2rem 0;
      }
      
      section h2 {
        font-size: 2rem;
      }
      
      .figure {
        padding: 1rem;
      }
      
      .download-btn {
        display: block;
        margin: 1rem auto;
        max-width: 280px;
      }
    }

    /* Modal Styling */
    .modal {
      display: none;
      position: fixed;
      z-index: 10000;
      left: 0;
      top: 0;
      width: 100%;
      height: 100%;
      background-color: rgba(0, 0, 0, 0.5);
      backdrop-filter: blur(5px);
    }

    .modal-content {
      background-color: var(--bg-primary);
      margin: 15% auto;
      padding: 2rem;
      border-radius: 15px;
      width: 90%;
      max-width: 500px;
      box-shadow: var(--shadow-strong);
      position: relative;
      animation: modalSlideIn 0.3s ease-out;
    }

    @keyframes modalSlideIn {
      from {
        opacity: 0;
        transform: translateY(-50px);
      }
      to {
        opacity: 1;
        transform: translateY(0);
      }
    }

    .modal-header {
      display: flex;
      justify-content: space-between;
      align-items: center;
      margin-bottom: 1rem;
      padding-bottom: 1rem;
      border-bottom: 2px solid var(--accent-warm);
    }

    .modal-header h3 {
      margin: 0;
      color: var(--primary-warm);
      font-family: var(--font-heading);
    }

    .modal-close {
      background: none;
      border: none;
      font-size: 1.5rem;
      cursor: pointer;
      color: var(--text-muted);
      transition: color 0.3s ease;
    }

    .modal-close:hover {
      color: var(--primary-warm);
    }

    .modal-body {
      margin-bottom: 1.5rem;
      line-height: 1.6;
    }

    .modal-footer {
      display: flex;
      justify-content: flex-end;
      gap: 1rem;
    }

    .modal-btn {
      padding: 0.5rem 1.5rem;
      border: none;
      border-radius: 25px;
      cursor: pointer;
      font-weight: 500;
      transition: all 0.3s ease;
    }

    .modal-btn-primary {
      background: var(--gradient-warm);
      color: white;
    }

    .modal-btn-primary:hover {
      transform: translateY(-2px);
      box-shadow: var(--shadow-medium);
    }

    .modal-btn-secondary {
      background: transparent;
      color: var(--text-secondary);
      border: 2px solid var(--text-muted);
    }

    .modal-btn-secondary:hover {
      background: var(--text-muted);
      color: white;
    }

    /* Animations */
    @keyframes fadeInUp {
      from {
        opacity: 0;
        transform: translateY(30px);
      }
      to {
        opacity: 1;
        transform: translateY(0);
      }
    }

    section {
      animation: fadeInUp 0.6s ease-out;
    }
  </style>
</head>
<body>

<!-- Toolbar with Home Button -->
<div class="toolbar">
  <div class="container">
    <a href="/"><i class="fas fa-home"></i> Home</a>
  </div>
</div>

<header>
  <h1>Cognitive Agentic AI: Probabilistic Novelty Detection for Continual Adaptation in HRI</h1>
</header>

<main>
<div class="container">
  <section>
    <h2>About the Paper</h2>
    <p>
      Adapting to novel tasks in human-robot interaction (HRI) is crucial for long-term autonomy, yet remains a major challenge for autonomous agents deployed in unpredictable open-world settings. This paper introduces CAPA-AI, a novel framework that integrates probabilistic novelty detection with continual post-deployment adaptation achieved via transfer learning to address this challenge. The framework's novelty detection component employs conditional probability and the Jaccard Index to identify unfamiliar tasks by quantifying their deviation from the agent's knowledge base of previously learned tasks. Upon detecting a novel task, the agent utilises transfer learning to repurpose prior knowledge and update its models without retraining from scratch. We detail the design of CAPA-AI, including an isolated learning phase for initial skill acquisition and the construction of a dynamic knowledge base. The complete system was deployed on a social robot in real-world HRI scenarios to evaluate its performance. Experimental results demonstrated that the agent accurately detects novel tasks and adapts to them, achieving adaptation and novelty detection accuracies of 80% and 89%, respectively. These findings underscore the efficacy of the proposed approach and highlight a significant step towards robust open-world deployment of AI agents in HRI, where continuous adaptation and the safe handling of unforeseen tasks are essential.
    </p>
    <div class="highlight">
      <i class="fas fa-lightbulb"></i> <b>Did you know?</b> Most deployed AI agents freeze after initial training—they can't tell when the world changes. CAPA-AI can!
    </div>
  </section>

  <div class="figure">
    <img src="capa-ai.png" alt="CAPA-AI continual learning agentic AI architecture for reinforcement learning and HRI" class="figure-large" loading="eager" width="800" height="600">
    <p><b>Figure 1:</b> Overview of the CAPA-AI architecture. A reinforcement learning (RL) agent is pre-trained in isolation, while a knowledge base stores task-specific information for novelty detection. When a novel task is detected during real-world operation, the agent leverages transfer learning or its own exploration to adapt, updating both its policy and knowledge base.</p>
  </div>

  <section>
    <h2>Continual Learning & Adaptation: Motivation</h2>
    <p>
      Autonomous robots operating in dynamic, human-centred environments constantly face unpredictability—no dataset or pre-training can prepare them for everything. Traditional AI systems are prone to <b>catastrophic forgetting</b> if retrained, or simply ignore novel tasks, which risks safety and erodes user trust.
    </p>
    <p>
      <b>CAPA-AI</b> addresses this by equipping the robot with two essential abilities:
    <ul>
      <li><b>Novelty detection:</b> Accurately identifies when an observed task or situation has not been encountered before.</li>
      <li><b>Continual adaptation:</b> Upon detecting novelty, the robot can re-use related prior knowledge (via transfer learning) to adapt, or gather new experience as needed—all without full retraining or human-in-the-loop supervision.</li>
    </ul>
    <div class="highlight">
      <i class="fas fa-info-circle"></i> This paves the way for true <b>open-world autonomy</b>—robots that can self-improve as the world changes.
    </div>
  </section>

  <section>
    <h2>How the CAPA-AI Architecture Works</h2>
    <h3>Reinforcement Learning & Vision Language Models in CAPA-AI</h3>
    <ul>
      <li><b>Isolated Learning Phase:</b> The RL agent is initially trained on a set of known tasks (e.g., using the RHM dataset). Task-specific experiences and environmental keywords are stored in an Agent Knowledge Base (AKB).</li>
      <li><b>Novelty Detection Module:</b> During real-world operation, incoming sensor data (video frames) are processed using vision-language models (e.g., LLaVA) and contextual keywords are extracted (e.g., via DeepSeek).</li>
      <li><b>Probabilistic Novelty Detection:</b> New keywords are compared with the AKB using conditional probability and the Jaccard Index, computing a posterior probability of task similarity. If the similarity is high (>90%), the agent uses its pre-trained model; for partial similarity (60-89%), it adapts via transfer learning. For genuinely novel cases (<60%), exploration is triggered.</li>
      <li><b>Transfer Learning:</b> The agent updates its RL policy using strategies from similar tasks, rapidly adapting to the new task and updating its AKB.</li>
    </ul>
    <div class="highlight">
      <i class="fas fa-robot"></i> <b>Innovation:</b> CAPA-AI uniquely combines <b>probabilistic reasoning, memory, transfer learning,</b> and <b>real-time feedback</b> to enable seamless, explainable adaptation in unpredictable settings.
    </div>
  </section>

  <section>
    <h2>Video Explanation</h2>
    <div class="figure">
      <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; border-radius: 12px; box-shadow: var(--shadow-medium);">
        <iframe src="https://www.youtube.com/embed/pTxR_r9Mo2c" 
                style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0; border-radius: 12px;"
                allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
                allowfullscreen
                title="CAPA-AI: Cognitive Agentic AI - Probabilistic Novelty Detection for Continual Adaptation in HRI">
        </iframe>
      </div>
      <p><b>Video:</b> Detailed explanation of CAPA-AI framework - how probabilistic novelty detection and transfer learning enable continual adaptation in human-robot interaction.</p>
    </div>
  </section>

  <div class="figure">
    <img src="novelty-detection.png" alt="Novelty detection results using probabilistic methods and Jaccard Index in continual learning for reinforcement learning agent in HRI" loading="lazy" width="700" height="500">
    <p><b>Figure 2:</b> Example result of the novelty detection pipeline. Posterior probabilities and the Jaccard Index are used to quantify how closely new observations match known tasks (here, the "Drinking" activity). This enables reliable detection and triggers adaptation only when truly necessary.</p>
  </div>

  <section>
    <h2>Step-by-Step Adaptation and Results</h2>
    <h3>Presented at IEEE RO-MAN 2025 Conference</h3>
    <ul>
      <li><b>Pre-training:</b> CAPA-AI is pre-trained using the RHM dataset on 14 daily human activities. For each, the agent stores both policy knowledge and a vocabulary of environmental/contextual keywords.</li>
      <li><b>Simulation Evaluation:</b> The framework is tested on the EatSense and Polar datasets (which contain new, partially overlapping tasks). CAPA-AI detects and adapts to novel activities, transferring knowledge from the most similar tasks.</li>
      <li><b>Real-World Deployment:</b> CAPA-AI is implemented on the ARI humanoid robot, interacting with users performing both familiar and unfamiliar tasks in real environments.</li>
    </ul>
    <div class="figure">
      <img src="eval-pipeline.png" alt="Evaluation workflow for CAPA-AI agent with simulation and real-world continual adaptation, leveraging reinforcement learning and transfer learning in machine learning" loading="lazy" width="750" height="550">
      <p><b>Figure 3:</b> Evaluation workflow: CAPA-AI is pre-trained, then deployed in both simulated (EatSense/Polar) and real-world HRI scenarios, where it processes sensory data and adapts in real time.</p>
    </div>
    <ul>
      <li><b>Sample Scenario:</b> In one real-world test, the robot observes the action "using tissue"—not seen during training. CAPA-AI's ND module classifies this as novel but similar to "cleaning," so transfer learning is triggered. The agent updates its behaviour, improving performance in subsequent encounters.</li>
      <li><b>Accuracy:</b> CAPA-AI achieves <b>89% novelty detection accuracy</b> and <b>80% adaptation accuracy</b> in real-world tests. The approach is robust to sensor noise and ambiguous activities.</li>
    </ul>
  </section>

  <div class="figure">
    <img src="R1.png" alt="CAPA-AI real-world test: drinking task correctly recognised by continual learning agent using reinforcement learning and vision language models in human-robot interaction" loading="lazy" width="400" height="300">
    <p><b>a)</b> Task: Drinking, CAPA-AI Decision: Drinking</p>
    <img src="R2.png" alt="CAPA-AI real-world novelty detection: using tissue task identified as novel and mapped to cleaning using transfer learning and contextual adaptation in HRI" loading="lazy" width="400" height="300">
    <p><b>b)</b> Task: Using Tissue, CAPA-AI Decision: Novelty, Similar Task: Cleaning</p>
    <img src="R3.png" alt="CAPA-AI agent adaptation: laying down task detected as novel but similar to sitting down, demonstrating explainable continual adaptation in real-world human-robot interaction" loading="lazy" width="400" height="300">
    <p><b>c)</b> Task: Laying, CAPA-AI Decision: Novelty, Similar Task: Sitting Down</p>
    <p>
      <b>Figure 4:</b> CAPA-AI real-world decisions: (a) "Drinking" correctly identified as familiar; (b) "Using tissue" detected as a novel action and mapped to "cleaning"; (c) "Lying down" treated as novel but similar to "sitting down," showing CAPA-AI's fine-grained, explainable adaptation.
    </p>
  </div>

  <section>
    <h2>Why It Matters</h2>
    <p>
      <b>CAPA-AI</b> advances the state of the art in robot autonomy and trust by:
    <ul>
      <li>Enabling <b>safe, continual adaptation</b> in dynamic environments—no more "frozen" agents!</li>
      <li>Providing <b>probabilistic, explainable decisions</b> on when to adapt and what to adapt from</li>
      <li>Reducing risk of catastrophic forgetting or inappropriate generalisation</li>
      <li>Improving HRI by making robots more reliable, responsive, and aware of their own limitations</li>
    </ul>
    <div class="highlight">
      <i class="fas fa-hands-helping"></i> <b>Impact:</b> This approach benefits social robotics, assistive technologies, service robots, and any AI deployed "in the wild."
    </div>
  </section>

  <section>
    <h2>Open Science & Collaboration</h2>
    <p>
      Interested in collaborating, adapting, or extending CAPA-AI? We support open, reproducible science and welcome new partnerships to push forward robust and adaptive agentic AI.
    </p>
    <div class="social-links">
      <a href="https://scholar.google.com/citations?user=zRG8t_oAAAAJ&hl=en" target="_blank" rel="noopener" title="Google Scholar">
        <i class="fas fa-graduation-cap"></i>
      </a>
      <a href="https://orcid.org/0009-0002-6416-3127" target="_blank" rel="noopener" title="ORCID">
        <i class="fab fa-orcid"></i>
      </a>
    </div>
  </section>

  <section>
    <h2>Full Paper & Code</h2>
    <div class="download-section">
      <a href="#" class="download-btn" onclick="showPaperDialog(event)">
        <i class="fas fa-download"></i> Download Full Paper
      </a>
      <a href="#" class="download-btn" onclick="showCodeDialog(event)">
        <i class="fas fa-code"></i> View Code
      </a>
    </div>
    <p style="margin-top:2rem;font-size:1rem;color:var(--text-muted);text-align:center;">
      <i class="fas fa-info-circle"></i> Research outputs will be available following conference presentation and publication.
    </p>
  </section>
</div>
</main>

<!-- Modal Dialogs -->
<div id="paperModal" class="modal">
  <div class="modal-content">
    <div class="modal-header">
      <h3><i class="fas fa-file-alt"></i> Full Paper Access</h3>
      <button class="modal-close" onclick="closeModal('paperModal')">&times;</button>
    </div>
    <div class="modal-body">
      <p>This paper will be available in the proceedings of <strong>IEEE RO-MAN 2025</strong> after the conference takes place in August 2025.</p>
      <p>For early access or collaboration inquiries, please contact:</p>
      <p><strong><i class="fas fa-envelope"></i> k.ghamati@herts.ac.uk</strong></p>
    </div>
    <div class="modal-footer">
      <button class="modal-btn modal-btn-secondary" onclick="closeModal('paperModal')">Close</button>
      <button class="modal-btn modal-btn-primary" onclick="copyEmail()">Copy Email</button>
    </div>
  </div>
</div>

<div id="codeModal" class="modal">
  <div class="modal-content">
    <div class="modal-header">
      <h3><i class="fas fa-code"></i> Source Code Access</h3>
      <button class="modal-close" onclick="closeModal('codeModal')">&times;</button>
    </div>
    <div class="modal-body">
      <p>To access the source code, datasets, and experimental materials for CAPA-AI, please contact our research team:</p>
      <p><strong><i class="fas fa-envelope"></i> k.ghamati@herts.ac.uk</strong></p>
      <p><i class="fas fa-info-circle"></i> We're committed to open science and collaborative research!</p>
    </div>
    <div class="modal-footer">
      <button class="modal-btn modal-btn-secondary" onclick="closeModal('codeModal')">Close</button>
      <button class="modal-btn modal-btn-primary" onclick="copyEmail()">Copy Email</button>
    </div>
  </div>
</div>

<script>
  function showPaperDialog(event) {
    event.preventDefault();
    document.getElementById('paperModal').style.display = 'block';
  }

  function showCodeDialog(event) {
    event.preventDefault();
    document.getElementById('codeModal').style.display = 'block';
  }

  function closeModal(modalId) {
    document.getElementById(modalId).style.display = 'none';
  }

  function copyEmail() {
    navigator.clipboard.writeText('k.ghamati@herts.ac.uk').then(function() {
      // Create a temporary success message
      const btn = event.target;
      const originalText = btn.innerHTML;
      btn.innerHTML = '<i class="fas fa-check"></i> Copied!';
      btn.style.background = '#28a745';
      setTimeout(() => {
        btn.innerHTML = originalText;
        btn.style.background = '';
      }, 2000);
    });
  }

  // Close modal when clicking outside
  window.onclick = function(event) {
    if (event.target.classList.contains('modal')) {
      event.target.style.display = 'none';
    }
  }

  // Close modal with Escape key
  document.addEventListener('keydown', function(event) {
    if (event.key === 'Escape') {
      const modals = document.querySelectorAll('.modal');
      modals.forEach(modal => {
        modal.style.display = 'none';
      });
    }
  });
</script>

<footer>
  <div class="container">
    <p>&copy; 2025 Khashayar Ghamati. All rights reserved.</p>
    <p style="font-size: 0.9rem; opacity: 0.8; margin-top: 1rem;">Advancing AI research for a better future</p>
  </div>
</footer>

</body>
</html>